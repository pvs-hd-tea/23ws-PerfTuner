Hello everyone, we are the perf tuner team and our project revolves around we have a
C++ function or a program and we have to convert it or optimize it using AVX and of course
via LLMs. So the progress for this week is that we have an optimized or a better version
of our perf tuner and we have thought about our tree of thoughts. Also we have worked
on the Gaussian elimination example by hand. This was the flow chart that we already presented
and we have implemented it and we have code ready for it. So it is working but there are
still some errors and issues that I still have to rectify and this is the initial prompt
that I am putting into the chat GPT API and as we already see there are a lot of specifics
that I really had to mention so that it produced proper results and further that we are looking
into examples we see that there are a lot of things that we really have to mention for
chat GPT to understand the kind of results that we want. This is where I am sort of stuck
right now. So as of now it is compiling. The results are compiling in the Python environment
which is the C++ program and the program which is vectorized. They are all compiling in the
Python environment. However one problem is that we are getting a higher execution time for AVX
program in comparison to C++ program and the reason is because in the program we are converting
the input data into vectorized form and then doing the processing. So this is taking more time. This
is the reason time is more. So I need to figure out a way to actually find out how to find the
execution time without this conversion.
So that is one thing and the other one is that I am getting the syntax of the command
is incorrect. This kind of output which is from the ID not from the script. So I am still figuring
out why this is not working because in a G++ environment it is perfectly compiling and giving
the results. So this is yet to be found out what is happening here. Yeah and then I like thought
a bit more in general because what we tried so far what we had the program and we tried to tell
GPT like optimize it using AVX in different ways but that didn't always work perfectly so I
tried to think of it bigger and constructed like a tree of thoughts where this is only a subtask
and where we have like results that are also good even if this subtask doesn't work and then I first
like all this is done by hand first and next week I try to make it like into a program and
the first task was if we have a C++ file I asked which subtasks are tackled to see if the program
actually can find what we are doing and this worked pretty fine. Actually it could structure
what we are doing in every step but there was a minor problem that it also said something like
C out or declaring a variable is actually a subtask but then we could ask in another
step there actually which subtask can we improve and then he found out that like declaring a
variable is not to improvement because it's just a language so he could actually find in like a
long file which are the problems that we can actually improve which I think is already pretty
interesting and then we could ask him how he would improve them and then he found different ways
telling for example numerical stability or storage because I just asked like very widely
but also parallelization he found and then we could ask him like how he would do parallelization
and then he said either multi-threaded programming or using AVX and this is like the first half of
the tree which is just about understanding what is actually the input which are the tasks which
we can tackle and how we could improve them and the red is then what like leads to that end what
we want yeah well we wouldn't continue a green is where we can actually continue and orange is
like potential to continue like if there would be like in I don't know five years if PerfQ
is still existing and someone decides to improve storage then he could actually get in there but
we will continue with the parallelization path and then the other question was how we can improve
it and so far we were always in this like left line that basically trying to tell how to make
better code this is like just an example and then also with the dots you see like still not
perfectly but then what we also found out when Alexander was doing the Gauss elimination that
sometimes just seems impossible telling chat GPT how to actually use AVX in some cases and in the
end we were basically telling him what we could write ourselves so that won't be any help but then
we thought what we actually still have we have like a solution done by hand and very often in
scientific programs there are tasks that occur all the time like transposing a matrix or doing
like a matrix vector product or doing a dot product and if we have like a database of 20 years then
that sub task and we already know them how to do them by hand and we teach chat GPT like chat GPT
gets the sub task we teach them which is the best solution just say like substitute it and if we
have like a long file where he does like 20 times dot product and we tell him to substitute it that's
already a big help so this could be like the one path that works if we have like a potential for
substitution the other case would of course still be to try that chat GPT actually optimizes it
himself but could also be that that not worked so in like if we check it and we came to the case
that both doesn't work we still have something that we found out that is the parallelization
potential because we divided the tasks and found out how we can improve them we found tasks where
we can parallelize and where we can use AVX and then if we have like in the worst case a file with
300 lines but we tell to the user in this three lines we think you could use AVX even if you don't
give the solution he knows where to look which is already a good but if we then actually find a
solution we for like every sub task we could try to merge them and give like a better C++ file plus
the information for the tasks where it didn't work so we have like three trials to use chat GPT to
make better code and hope that like at least some of them will work for some sub tasks and then now
where we are like which is still the biggest intellectual problem where we still need to think
and it's not just about like implementing it is this line where we try to make chat GPT to better
code without having knowledge about the problem and there we like still trying a bit around what
works because we want to have like a line of prompting that works for like any or in theory
for any problem and this is where we still need to think a bit. That's where I come in I looked at
the example from last week from Peter Bastian maybe remember it and I looked at this example
more deeply to find the obstacles that chat GPT has to give us a correct code. As a brief recap
we have the Gaussian elimination system so you have a system of linear equations and by
like step by step eliminating each variable you get the solution for this system of linear
equations and you can do this just as you've learned in high school step by step however you
can also do this by changing the order of what you add like which rows you add on top of which
one and you do this for casual use so you can do it quicker and so I made a sketch of the entire
matrix and you divide it up into certain blocks denoted by the black squares and then how you
can do it you can first start with the upper left block in the left corner and then you do the next
row and then the column. The reason why you do this this way is because you need the result of
the first block to be able to do the rest of the row and the block and then you can do the rest of
the matrix. So that's behind it let's first look at the upper left block so this code is only
responsible for this upper left block here and then you can see the unrolling of the loop you
in the very upper loop you have a step size of B which is the size of the block and then you have
some other loops and when you come to this line here you can do the actual arithmetics and you
can use AVX functions very nicely however there's a problem if you look at this loop actually the
times this loop runs changes with K and then actually in the end it might happen that this
loop only runs for three times or two times and then you load your elements into the register and
load it back then you actually overwrite other elements of the matrix they actually overwrite
elements here and this obviously gives you wrong results and Chachapiti is not aware of that at
all. I looked at I wanted to optimize it by hand and I'm normally looking at the red square which
is the bulk of it and here you actually can do a really nice optimization but also you have to be
really careful this is the last so this is the command you want to substitute however there are
two problems if you only look at this loop and you want to kind of change the step size here to
four to use the AVX intrinsic but there are two problems the first problem is this element stays
the same and you add onto this element and there are no such commands intrinsic commands to do that
and the second problem is here you change K here works nicely but here you have to change the K
but since the way this matrix is stored if I load it only get I can tell them okay load this element
and the next three ones in memory but the next three in memory are not the next K one so K plus
one K plus two but J plus one J plus two so you look wrote the wrong elements and also Chachapiti
is not capable of doing that if you want to do it correctly you actually can see well the loop above
it it's possible to change the step size to four then it works nicely then it's no problem and then
you can do it and this runs fast and gives the correct results but this I've done by hand then
I tried Chachapiti to give me results and I really had to give him very very specific commands which
are very specific to this problem and obviously we want a more general approach so that we can
not only use this example which we already have and now we are looking maybe at this example another
example this is maybe also a question this is connecting to the last question from Thomas that
like we really need to figure out what are the obstacles and how can we in a general form tell
Chachapiti to tackle these obstacles and yeah it's actually I understand why Chachapiti took so long
it also took me quite a while to understand the obstacle what's what's going on here yeah I could
it worked when I told him I can change the step size only for the rest matrix only in the J loop
and then even gave me a wrong result because he actually moved this command outside of K which
couldn't even compile afterwards because K is not known outside the loop I had to tell him move it in
the loop and then I got the correct result which is like way too specific but I think if we now look at
another example maybe the transpose example we might get a feeling what are in general approach
to tackle these obstacles. Let me stop the recording
